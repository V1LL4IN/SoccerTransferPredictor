# -*- coding: utf-8 -*-
"""ProyectoFinalIA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TOKC8N0xnos7kU6bq5_PbAX0QPD5tCGz
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import missingno as msno
from sklearn.metrics import mean_absolute_error, classification_report, confusion_matrix, multilabel_confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVC #SVC clasificacion SVR regresion
from sklearn.neighbors import KNeighborsClassifier
import seaborn as sns
import matplotlib.pyplot as plt
from keras.layers import Dropout
import numpy as np

df = pd.read_csv("england-premier-league-players-2018-to-2019-stats.csv", encoding='latin1',delimiter= ';')

df

df.info()

df = df.drop(['age.1','birthday_GMT','league','season'],axis = 1)

df = df.drop(['rank_in_league_top_attackers','rank_in_league_top_midfielders','rank_in_league_top_defenders','rank_in_club_top_scorer'],axis = 1)

df = df.drop(['full_name'],axis = 1)

le = LabelEncoder()
df['nationality'] = le.fit_transform(df['nationality'])
df['position'] = le.fit_transform(df['position'])
df['current_club'] = le.fit_transform(df['current_club'])

df

"""#PEARSON"""

sns.set(style="whitegrid",font_scale=1)
plt.figure(figsize=(20,20))
plt.title("Indice Correlacion Pearson")
sns.heatmap(df.corr(),vmax=0.8, cmap="GnBu", annot=True, annot_kws={ 'size' :9})

df = df.drop(['minutes_played_overall','appearances_overall','conceded_overall'],axis = 1)

df = df.drop(['clean_sheets_overall','goals_per_90_overall','assists_overall','minutes_played_home','minutes_played_away'],axis = 1)

df = df.drop(['goals_overall','appearances_home','appearances_away','goals_involved_per_90_overall'],axis = 1)

df = df.drop(['clean_sheets_home','clean_sheets_away','min_per_match','goals_per_90_home','goals_per_90_away','conceded_away'],axis = 1)

sns.set(style="whitegrid",font_scale=1)
plt.figure(figsize=(20,20))
plt.title("Indice Correlacion Pearson")
sns.heatmap(df.corr(),vmax=0.8, cmap="GnBu", annot=True, annot_kws={ 'size' :9})

"""#ATIPICOS"""

df.info()

plt.figure(figsize=(15,15))
col = df.columns[:-1]
for i in enumerate(col):
  plt.subplot(10,4,i[0]+1)
  sns.boxplot(x=i[1], data = df)

for i in col:
  q1 = df[i].quantile(0.05)
  q4 = df[i].quantile(0.95)
  df[i][df[i]<=q1] = q1
  df[i][df[i]>=q4] = q4

plt.figure(figsize=(15,15))
col = df.columns[:-1]
for i in enumerate(col):
  plt.subplot(10,4,i[0]+1)
  sns.boxplot(x=i[1], data = df)

"""#IMPUTACION"""

df.isnull().sum()

"""#ASIGNACION VARIABLE"""

X = df.drop(['TransferMarket'],axis=1)
y = df['TransferMarket']

X

y

y.value_counts()

"""#BALANCEO"""

randomOverSampler = RandomOverSampler()
X_randomOverSampler, y_randomOverSampler = randomOverSampler.fit_resample(X,y)


randomUnderSampler = RandomUnderSampler()
X_randomUnderSampler, y_randomUnderSampler = randomUnderSampler.fit_resample(X,y)

smote = SMOTE()
X_smote, y_smote = smote.fit_resample(X,y)

y_randomOverSampler.value_counts()

y_randomUnderSampler.value_counts()

y_smote.value_counts()

y = pd.get_dummies(y)
y1_randomOverSampler = le.fit_transform(y_randomOverSampler)
y_randomOverSampler = pd.get_dummies(y_randomOverSampler)
y1_randomUnderSampler = le.fit_transform(y_randomUnderSampler)
y_randomUnderSampler = pd.get_dummies(y_randomUnderSampler)
y1_smote = le.fit_transform(y_smote)
y_smote = pd.get_dummies(y_smote)

y

"""#NORMALIZACION"""

scaler = MinMaxScaler()
scaler.fit(X_randomOverSampler)
#Guardar el scaler en un archivo pickles
X_randomOverSampler = scaler.transform(X_randomOverSampler)

import pickle
scaler_filename = 'scaler.pkl'
with open(scaler_filename, 'wb') as file:
    pickle.dump(scaler, file)

"""#OVERSAMPLING ANN"""

X_train, X_test, y_train, y_test = train_test_split(X_randomOverSampler, y_randomOverSampler, test_size=0.2, random_state=10)

from tensorflow.keras import regularizers
from keras.optimizers import SGD

ann = Sequential()
ann.add(Dense(20, activation="relu", kernel_regularizer=regularizers.l2(0.01)))
ann.add(Dropout(0.5))
ann.add(Dense(10, activation="relu", kernel_regularizer=regularizers.l2(0.01)))
ann.add(Dense(2, activation="sigmoid"))
ann.compile(optimizer="SGD", loss="binary_crossentropy", metrics=['accuracy'])

ann.fit(x = X_train, y= y_train,validation_data=(X_test,y_test),
          epochs = 200, batch_size=8, verbose=1)

loss = pd.DataFrame(ann.history.history)
plt.figure(figsize = (10,10))
sns.lineplot(data=loss,lw=3)
sns.despine()

y_train_predict = ann.predict(X_train)
y_test_predict = ann.predict(X_test)

for index, value in enumerate(y_train_predict):
    if value[0] > 0.5:
        y_train_predict[index][0] = 1
    else:
        y_train_predict[index][0] = 0

    if value[1] > 0.5:
        y_train_predict[index][1] = 1
    else:
        y_train_predict[index][1] = 0

print(multilabel_confusion_matrix(y_train,y_train_predict))
print(classification_report(y_train,y_train_predict))

for index, value in enumerate(y_test_predict):
    if value[0] > 0.5:
        y_test_predict[index][0] = 1
    else:
        y_test_predict[index][0] = 0

    if value[1] > 0.5:
        y_test_predict[index][1] = 1
    else:
        y_test_predict[index][1] = 0

print(multilabel_confusion_matrix(y_test,y_test_predict))
print(classification_report(y_test,y_test_predict))

ann.save("modeloProyecto.h5")

"""#OVERSAMPLING SVM"""

scaler = MinMaxScaler()
scaler.fit(X_randomOverSampler)
#Guardar el scaler en un archivo pickles
X_randomOverSampler = scaler.transform(X_randomOverSampler)

X_train, X_test, y_train, y_test = train_test_split(X_randomOverSampler, y1_randomOverSampler,test_size=0.2,random_state=20)

y_train

svc = SVC(kernel='poly').fit(X_train,y_train)#poly linear (para lineal), sigmod rbf

print(svc.score(X_train,y_train))

y_train_predict = svc.predict(X_train)
y_test_predict = svc.predict(X_test)

print(confusion_matrix(y_train,y_train_predict))
print(classification_report(y_train,y_train_predict))

print(confusion_matrix(y_test,y_test_predict))
print(classification_report(y_test,y_test_predict))

"""#OVERSAMPLING KNN"""

X_train, X_test, y_train, y_test = train_test_split(X_randomOverSampler, y_randomOverSampler,test_size=0.2,random_state=20)

error = []
for i in range(1,10):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(X_train,y_train)
  predict_test = knn.predict(X_test)
  error.append(np.mean(predict_test!=y_test))

plt.figure(figsize=(15,15))
plt.plot(range(1,10),error,color='b',marker='o',markerfacecolor='r')
plt.xlabel('K')
plt.ylabel('error')

knn_ = KNeighborsClassifier(n_neighbors=3,metric='euclidean')#euclidean manhatan -- minkowski en espacios 3d
knn_.fit(X_train,y_train)
y_predict_knn = knn.predict(X_train)

print(accuracy_score(y_train,y_predict_knn))

y_predict_knn_test = knn.predict(X_test)

print(accuracy_score(y_test,y_predict_knn_test))

print(multilabel_confusion_matrix(y_train,y_predict_knn))
print(classification_report(y_train,y_predict_knn))

print(multilabel_confusion_matrix(y_test,y_predict_knn_test))
print(classification_report(y_test,y_predict_knn_test))

"""#UNDERSAMPLING ANN"""

scaler = MinMaxScaler()
scaler.fit(X_randomUnderSampler)
#Guardar el scaler en un archivo pickles
X_randomUnderSampler = scaler.transform(X_randomUnderSampler)

X_train, X_test, y_train, y_test = train_test_split(X_randomUnderSampler, y_randomUnderSampler, test_size=0.2, random_state=20)

from tensorflow.keras import regularizers
from keras.optimizers import SGD

ann = Sequential()
ann.add(Dense(21, activation="relu", kernel_regularizer=regularizers.l2(0.01)))
ann.add(Dropout(0.5))
ann.add(Dense(12, activation="relu", kernel_regularizer=regularizers.l2(0.01)))
ann.add(Dense(2, activation="sigmoid"))
ann.compile(optimizer="SGD", loss="binary_crossentropy", metrics=['accuracy'])

ann.fit(x = X_train, y= y_train,validation_data=(X_test,y_test),
          epochs = 250, batch_size=8, verbose=1)

loss = pd.DataFrame(ann.history.history)
plt.figure(figsize = (10,10))
sns.lineplot(data=loss,lw=3)
sns.despine()

y_train_predict = ann.predict(X_train)
y_test_predict = ann.predict(X_test)

for index, value in enumerate(y_train_predict):
    if value[0] > 0.5:
        y_train_predict[index][0] = 1
    else:
        y_train_predict[index][0] = 0

    if value[1] > 0.5:
        y_train_predict[index][1] = 1
    else:
        y_train_predict[index][1] = 0

print(multilabel_confusion_matrix(y_train,y_train_predict))
print(classification_report(y_train,y_train_predict))

for index, value in enumerate(y_test_predict):
    if value[0] > 0.5:
        y_test_predict[index][0] = 1
    else:
        y_test_predict[index][0] = 0

    if value[1] > 0.5:
        y_test_predict[index][1] = 1
    else:
        y_test_predict[index][1] = 0

print(multilabel_confusion_matrix(y_test,y_test_predict))
print(classification_report(y_test,y_test_predict))

"""# UNDERSAMPLING SVM"""

scaler = MinMaxScaler()
scaler.fit(X_randomUnderSampler)
#Guardar el scaler en un archivo pickles
X_randomUnderSampler = scaler.transform(X_randomUnderSampler)

X_train, X_test, y_train, y_test = train_test_split(X_randomUnderSampler, y1_randomUnderSampler,test_size=0.2,random_state=20)

svc = SVC(kernel='poly').fit(X_train,y_train)#poly linear (para lineal), sigmod rbf

print(svc.score(X_train,y_train))

y_train_predict = svc.predict(X_train)
y_test_predict = svc.predict(X_test)

print(confusion_matrix(y_train,y_train_predict))
print(classification_report(y_train,y_train_predict))

print(confusion_matrix(y_test,y_test_predict))
print(classification_report(y_test,y_test_predict))

"""# UNDERSAMPLING KNN"""

scaler = MinMaxScaler()
scaler.fit(X_randomUnderSampler)
#Guardar el scaler en un archivo pickles
X_randomUnderSampler = scaler.transform(X_randomUnderSampler)

X_train, X_test, y_train, y_test = train_test_split(X_randomUnderSampler, y_randomUnderSampler,test_size=0.2,random_state=20)

plt.figure(figsize=(15,15))
plt.plot(range(1,10),error,color='b',marker='o',markerfacecolor='r')
plt.xlabel('K')
plt.ylabel('error')

knn_ = KNeighborsClassifier(n_neighbors=5,metric='euclidean')#euclidean manhatan -- minkowski en espacios 3d
knn_.fit(X_train,y_train)
y_predict_knn = knn.predict(X_train)

print(accuracy_score(y_train,y_predict_knn))

y_predict_knn_test = knn.predict(X_test)

print(accuracy_score(y_test,y_predict_knn_test))

print(multilabel_confusion_matrix(y_train,y_predict_knn))
print(classification_report(y_train,y_predict_knn))

print(multilabel_confusion_matrix(y_test,y_predict_knn_test))
print(classification_report(y_test,y_predict_knn_test))